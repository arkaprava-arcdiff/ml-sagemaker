{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mplfinance\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mplfinance as mpf\n",
    "plt.style.use('seaborn-deep')\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'MSFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    return datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "df = pd.read_csv(symbol+'.csv',  parse_dates = True, index_col=0, date_parser=parse)\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Adj_close', 'Volume']\n",
    "df.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First observation date: %s \\nLast observation date: %s' % (df.index[0].date(), df.index[-1].date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Date'], inplace=True, ascending=True)\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.var(df.Close - df.Adj_close))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Adj_close'], inplace = True, axis = 1)\n",
    "c_names = [name for name in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpf.plot(df.iloc[-50:,:], type='candle', volume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values\n",
    "\n",
    "num_f = len(df.columns)\n",
    "\n",
    "groups = [x for x in range(num_f)]\n",
    "\n",
    "plt.figure(figsize = (12,16))\n",
    "\n",
    "i = 1\n",
    "for group in groups:\n",
    "    plt.subplot(len(groups), 1, i)\n",
    "    plt.plot(values[:, group])\n",
    "    plt.title(df.columns[group], y=0.85, loc='center')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, c_names, n_in=1, n_out=1, dropnan=True):\n",
    "    '''\n",
    "    This function reformats the dataset the way it can be fed to the LSTM.\n",
    "    '''\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "   \n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "\n",
    "        cols.append(df.shift(i))\n",
    "        names += ['%s(t-%d)' % (n, i) for n in c_names]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % n) for n in c_names]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (n, i)) for n in c_names]\n",
    "   \n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "n_days_back = 21\n",
    "n_days_future = 1\n",
    "n_features = num_f\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, c_names, n_days_back, n_days_future)\n",
    "\n",
    "print(reframed.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = n_days_back * n_features\n",
    "\n",
    "target_idx = [reframed.columns.to_list().index(col) for col in reframed.columns[n_obs:] if 'Open' in col]\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "n_train_days = 2000\n",
    "\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train[:, :n_obs], train[:, target_idx]\n",
    "test_X, test_y = test[:, :n_obs], test[:, target_idx]\n",
    "\n",
    "# reshape input to fit the LSTM network requirements: [n_samples, window, n_features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_days_back, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_days_back, n_features))\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(train_y.shape[1]))\n",
    "\n",
    "checkpoint = ModelCheckpoint('w.hdf5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callback_list = [checkpoint]\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = root_mean_squared_error)\n",
    "\n",
    "t = model.fit(train_X, train_y, epochs=50,\n",
    "              batch_size=32,\n",
    "              validation_data=(test_X, test_y),\n",
    "              verbose=0,\n",
    "              callbacks = callback_list,\n",
    "              shuffle=False)\n",
    "\n",
    "model.load_weights('w.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.figure(figsize = (9,7))\n",
    "plt.title('Training Loss / Validation Loss')\n",
    "plt.plot(t.history['loss'], 'tab:red', label='Training loss')\n",
    "plt.plot(t.history['val_loss'], 'tab:blue', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "# invert scaling\n",
    "yhat_inv = yhat / scaler.scale_[0]\n",
    "y_inv = test_y / scaler.scale_[0]\n",
    "\n",
    "# reshape back\n",
    "yhat_inv_rshp = yhat_inv.reshape((-1,1))\n",
    "y_inv_rshp = y_inv.reshape((-1,1))\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = math.sqrt(mean_squared_error(y_inv_rshp, yhat_inv_rshp))\n",
    "print('Test set RMSE: %.2f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,7))\n",
    "plt.title('Real data vs Predicted on the Test set')\n",
    "plt.plot(y_inv_rshp, 'tab:green', label='Real data')\n",
    "plt.plot(yhat_inv_rshp, 'tab:blue', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial set size: {df.shape[0]}')\n",
    "print(f'Train set X size: {train_X.shape[0]}, train set y size: {train_y.shape[0]}')\n",
    "print(f'Test set X size: {test_X.shape[0]}, test set y size: {test_y.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = reframed.iloc[-1:, -n_obs:]\n",
    "last_day = last_day.values\n",
    "last_day = last_day.reshape((-1, n_days_back, n_features))\n",
    "\n",
    "t_plus_one = model.predict(last_day)\n",
    "t_plus_one /= scaler.scale_[0]\n",
    "print('Last observation\\'s date in the dateset is %s\\nLast observation\\'s value is %.2f' % (df.index[-1].date(), df.iloc[-1, 0]))\n",
    "print('\\nPredicted observation\\'s date is %s\\nPredicted observation\\'s value is %.2f' % (df.index[-1].date() + datetime.timedelta(days=1), t_plus_one))\n",
    "print('\\nReal value for %s is %.2f' % (df.index[-1].date() + datetime.timedelta(days=1), yf.Ticker(symbol).history(period='1d')['Close'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
